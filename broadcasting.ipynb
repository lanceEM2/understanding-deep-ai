{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding 3's and 7's from our MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download a sample of MNIST that contains images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('valid'),Path('train')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset follows a common layout for machine learning datasets: separate folders for the training set and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/7'),Path('train/3')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a folder of 3s, and a folder of 7s. In machine learning parlance, we say that \"3\" and \"7\" are the labels (or targets) in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png'),Path('train/3/10093.png'),Path('train/3/10097.png'),Path('train/3/10099.png'),Path('train/3/10116.png'),Path('train/3/10125.png'),Path('train/3/10137.png'),Path('train/3/10141.png'),Path('train/3/10144.png'),Path('train/3/10155.png'),Path('train/3/10161.png')...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCdP02+1a8W006znu7l+VigjLsQOpwO1dlb/CjVnkS3vNb8O6dqDkKtheaiFn3Hou1QcE8YBPcVg+LfCGqeCtYXS9WEPnvEJlML7lKEkA547qawatafqd/pN2LvTb24s7lQQJbeQowB6jI5r1D4Y6b4OvdXtdf8S+K45NY85phY3W6MeaCdrSTNw3IDcd8ZzyKx/i5pXiiLxMNZ8RC1kjvx/os1nJvh2KOFU8HgEHkc5zXntWdP0681a/hsbC3kubqY7Y4oxlmPXiu68OfBzxPq1yJNVtW0XTI/mnu73CbF74UkEn64HvVn4r+LdI1GDR/C3h2QzaTosXli5JJ858BeM9QAOvck9sV5nU1rdXFjdR3VpPLb3ETbo5YnKOh9QRyDV7UfE2v6vbi31PXNSvYA24RXN3JIufXDEjNZdFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9UlEQVR4AWNgGGSAEe4e2Upda8b/mwSvnloAF4MyDJY9+Pv31ZG/QPASTS72y8+/u/W4OFi4DiFLsoCV8XEyvCy9BGT++cfAsBlNJ7OICD9YSPvB369eaJJw7s+/X+vgHBQGX+r9vz9qUIRgHO5l74FO3S0H46PQAj9+gTzy4mo+E4o4lKOdlHQBJL9bDJssAwOncTlQ1ge7JAMD4/a/f7uhkhjm///PwHAXl87Qn3//quCQtLn29+9abuySSd///n3EiVVOa9ofYKSYostpFWvZFM//8Pfvr/WS6HIMu0GeB4KjYRhSDAzpYKkXzohUg0URtYQA/HZrR+ekLi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a computer, everything is represented as a number. To view the numbers that make up this image, we have to convert it to a NumPy array or a PyTorch tensor. For instance, here's what a section of the image looks like, converted to a NumPy array:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4:10 for rows: This means you are selecting rows from index 4 (inclusive) to index 10 (exclusive). So, it includes rows 4, 5, 6, 7, 8, and 9 (a total of 6 rows).\n",
    "\n",
    "4:10 for columns: Similarly, this means you are selecting columns from index 4 (inclusive) to index 10 (exclusive). So, it includes columns 4, 5, 6, 7, 8, and 9 (a total of 6 columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as a PyTorch tensor\n",
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can slice the array to pick just the part with the top of the digit in it, and then use a Pandas DataFrame to color-code the values using a gradient, which shows us clearly how the image is created from the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_64910_row0_col0, #T_64910_row0_col1, #T_64910_row0_col2, #T_64910_row0_col3, #T_64910_row0_col4, #T_64910_row0_col5, #T_64910_row0_col6, #T_64910_row0_col7, #T_64910_row0_col8, #T_64910_row0_col9, #T_64910_row0_col10, #T_64910_row0_col11, #T_64910_row0_col12, #T_64910_row0_col13, #T_64910_row0_col14, #T_64910_row0_col15, #T_64910_row0_col16, #T_64910_row0_col17, #T_64910_row1_col0, #T_64910_row1_col1, #T_64910_row1_col2, #T_64910_row1_col3, #T_64910_row1_col4, #T_64910_row1_col15, #T_64910_row1_col16, #T_64910_row1_col17, #T_64910_row2_col0, #T_64910_row2_col1, #T_64910_row2_col2, #T_64910_row2_col15, #T_64910_row2_col16, #T_64910_row2_col17, #T_64910_row3_col0, #T_64910_row3_col15, #T_64910_row3_col16, #T_64910_row3_col17, #T_64910_row4_col0, #T_64910_row4_col6, #T_64910_row4_col7, #T_64910_row4_col8, #T_64910_row4_col9, #T_64910_row4_col10, #T_64910_row4_col15, #T_64910_row4_col16, #T_64910_row4_col17, #T_64910_row5_col0, #T_64910_row5_col5, #T_64910_row5_col6, #T_64910_row5_col7, #T_64910_row5_col8, #T_64910_row5_col9, #T_64910_row5_col15, #T_64910_row5_col16, #T_64910_row5_col17, #T_64910_row6_col0, #T_64910_row6_col1, #T_64910_row6_col2, #T_64910_row6_col3, #T_64910_row6_col4, #T_64910_row6_col5, #T_64910_row6_col6, #T_64910_row6_col7, #T_64910_row6_col8, #T_64910_row6_col9, #T_64910_row6_col14, #T_64910_row6_col15, #T_64910_row6_col16, #T_64910_row6_col17, #T_64910_row7_col0, #T_64910_row7_col1, #T_64910_row7_col2, #T_64910_row7_col3, #T_64910_row7_col4, #T_64910_row7_col5, #T_64910_row7_col6, #T_64910_row7_col13, #T_64910_row7_col14, #T_64910_row7_col15, #T_64910_row7_col16, #T_64910_row7_col17, #T_64910_row8_col0, #T_64910_row8_col1, #T_64910_row8_col2, #T_64910_row8_col3, #T_64910_row8_col4, #T_64910_row8_col13, #T_64910_row8_col14, #T_64910_row8_col15, #T_64910_row8_col16, #T_64910_row8_col17, #T_64910_row9_col0, #T_64910_row9_col1, #T_64910_row9_col2, #T_64910_row9_col3, #T_64910_row9_col4, #T_64910_row9_col16, #T_64910_row9_col17, #T_64910_row10_col0, #T_64910_row10_col1, #T_64910_row10_col2, #T_64910_row10_col3, #T_64910_row10_col4, #T_64910_row10_col5, #T_64910_row10_col6, #T_64910_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row1_col6, #T_64910_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row1_col8, #T_64910_row1_col9, #T_64910_row1_col10, #T_64910_row2_col5, #T_64910_row2_col6, #T_64910_row2_col7, #T_64910_row2_col11, #T_64910_row2_col12, #T_64910_row2_col13, #T_64910_row3_col4, #T_64910_row3_col12, #T_64910_row3_col13, #T_64910_row4_col1, #T_64910_row4_col2, #T_64910_row4_col3, #T_64910_row4_col12, #T_64910_row4_col13, #T_64910_row5_col12, #T_64910_row6_col11, #T_64910_row9_col11, #T_64910_row10_col11, #T_64910_row10_col12, #T_64910_row10_col13, #T_64910_row10_col14, #T_64910_row10_col15, #T_64910_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row2_col4, #T_64910_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row2_col8, #T_64910_row2_col14, #T_64910_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row2_col9, #T_64910_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row2_col10, #T_64910_row7_col10, #T_64910_row8_col8, #T_64910_row8_col10, #T_64910_row9_col8, #T_64910_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row3_col7, #T_64910_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row5_col2, #T_64910_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row5_col4, #T_64910_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row5_col10, #T_64910_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row5_col13, #T_64910_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row6_col10, #T_64910_row7_col11, #T_64910_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row8_col9, #T_64910_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_64910_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row10_col8, #T_64910_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_64910_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_64910\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_64910_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_64910_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_64910_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_64910_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_64910_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_64910_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_64910_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_64910_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_64910_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_64910_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_64910_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_64910_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_64910_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_64910_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_64910_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_64910_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_64910_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_64910_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_64910_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_64910_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_64910_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_64910_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_64910_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_64910_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_64910_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_64910_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_64910_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_64910_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_64910_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_64910_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_64910_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_64910_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_64910_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_64910_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_64910_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_64910_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_64910_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_64910_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_64910_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_64910_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_64910_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_64910_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_64910_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_64910_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_64910_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_64910_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_64910_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_64910_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_64910_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_64910_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_64910_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_64910_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_64910_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_64910_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_64910_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_64910_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_64910_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_64910_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_64910_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_64910_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_64910_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_64910_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_64910_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_64910_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_64910_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_64910_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_64910_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_64910_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_64910_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_64910_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_64910_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_64910_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_64910_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_64910_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_64910_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_64910_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_64910_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_64910_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_64910_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_64910_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_64910_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_64910_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_64910_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_64910_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_64910_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_64910_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_64910_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_64910_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_64910_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_64910_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_64910_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_64910_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_64910_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_64910_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_64910_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_64910_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_64910_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_64910_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_64910_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_64910_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_64910_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_64910_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_64910_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_64910_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_64910_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_64910_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_64910_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_64910_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_64910_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_64910_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_64910_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_64910_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_64910_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_64910_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_64910_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_64910_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_64910_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_64910_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_64910_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_64910_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_64910_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_64910_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_64910_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_64910_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_64910_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_64910_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_64910_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_64910_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_64910_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_64910_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_64910_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_64910_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_64910_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_64910_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_64910_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_64910_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_64910_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_64910_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_64910_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_64910_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_64910_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_64910_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_64910_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_64910_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_64910_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_64910_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_64910_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_64910_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_64910_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_64910_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_64910_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_64910_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_64910_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_64910_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_64910_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_64910_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_64910_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_64910_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_64910_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_64910_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_64910_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_64910_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_64910_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_64910_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_64910_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_64910_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_64910_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_64910_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_64910_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_64910_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_64910_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_64910_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_64910_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_64910_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_64910_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_64910_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_64910_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_64910_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_64910_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_64910_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_64910_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_64910_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_64910_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_64910_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_64910_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_64910_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_64910_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_64910_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_64910_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_64910_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_64910_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_64910_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_64910_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_64910_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_64910_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_64910_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_64910_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_64910_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_64910_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_64910_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_64910_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_64910_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_64910_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_64910_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_64910_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_64910_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_64910_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_64910_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_64910_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_64910_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_64910_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_64910_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_64910_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_64910_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_64910_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_64910_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_64910_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb47ec81d50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the background white pixels are stored as the number 0, black is the number 255, and shades of gray are between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how about we find the average pixel value for every pixel of the 3s, then do the same for the 7s. This will give us two group averages, defining what we might call the \"ideal\" 3 and 7. Then, to classify an image as one digit or the other, we see which of these two ideal digits the image is most similar to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a tensor containing all of our 3s and 7s stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have tensors (which Jupyter by default will print as values), rather than PIL images (which Jupyter by default will display as images), we need to use fastai's show_image function to display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. To do this we first combine all the images in this list into a single three-dimensional tensor. The most common way to describe such a tensor is to call it a *rank-3 tensor*. We often need to stack up individual tensors in a collection into a single tensor. Unsurprisingly, PyTorch comes with a function called *stack* that we can use for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most important attribute of a tensor is its shape. This tells you the length of each axis. In this case, we can see that we have 6,131 images, each of size 28Ã—28 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of a tensor's shape is its rank(the number of axes or dimensions in a tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_threes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a tensor's rank directly with ndim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute what the ideal 3 looks like. We calculate the mean of all the image tensors by taking the mean along dimension 0 of our stacked, rank-3 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean3.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are two main ways data scientists measure distance in this context:\n",
    "\n",
    "Take the mean of the absolute value of differences (absolute value is the function that replaces negative values with positive values). This is called the *mean absolute difference* or *L1 norm*.\n",
    "Take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring). This is called the *root mean squared error (RMSE)* or *L2 norm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try both of these now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_3_abs = (a_3 - mean3).abs().mean()\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_7_abs = (a_3 - mean7).abs().mean()\n",
    "dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\n",
    "dist_7_abs,dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both metrics show that a_3 is closer to mean3 than to mean7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already provides both of these as loss functions. You'll find these inside torch.nn.functional, which the PyTorch team recommends importing as F (and is available by default under that name in fastai):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mse stands for mean squared error, and l1 refers to the standard mathematical jargon for mean absolute value (in math it's called the L1 norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy arrays and Pytorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays, unlike Pytorch tensors, does not support using the GPU or calculating gradients, which are both critical for deep learning. NumPy arrays and PyTorch tensors can finish computations many thousands of times faster than using pure Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A NumPy array is a multidimensional table of data, with all items of the same type. Since that can be any type at all, they can even be arrays of arrays, with the innermost arrays potentially being different sizesâ€”this is called a \"jagged array.\"\n",
    "A PyTorch tensor is nearly the same thing as a NumPy array, but cannot be jagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is slow compared to many languages. C language that is very fast compared to Python. To take advantage of its speed while programming in Python, try to avoid as much as possible writing loops, and replace them by commands that work directly on arrays or tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an array or tensor, pass a list (or list of lists, or list of lists of lists, etc.) to array() or tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2,3],[4,5,6]]\n",
    "arr = array (data)\n",
    "tns = tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr  # numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns  # pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select a row (note that, like lists in Python, tensors are 0-indexed so 1 refers to the second row/column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a column, by using : to indicate all of the first axis (we sometimes refer to the dimensions of tensors/arrays as axes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python slice syntax ([start:end] with end being excluded) to select part of a row or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can use the standard operators such as +, -, *, /:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4],\n",
       "        [5, 6, 7]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 3.0000, 4.5000],\n",
       "        [6.0000, 7.5000, 9.0000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns*1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Metrics using Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset, in order to tell us how good our model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've discussed, we want to calculate our metric over a validation set. This is so that we don't inadvertently overfitâ€”that is, train a model to work well only on our training data. As it turns out, the creators of the MNIST dataset have already done this for us. Do you remember how there was a whole separate directory called valid? That's what this directory is for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to start with, let's create tensors for our 3s and 7s from that directory. These are the tensors we will use to calculate a metric measuring the quality of our first-try model, which measures distance from an ideal image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a simple function that calculates the mean absolute error.\n",
    ".mean((-1, -2)): Computes the mean across the last two dimensions of the tensor.\n",
    "\n",
    "-1 refers to the last dimension.\n",
    "\n",
    "-2 refers to the second-to-last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "mnist_distance(a_3, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in order to calculate a metric for overall accuracy, we will need to calculate the distance to the ideal 3 for every image in the validation set. How do we do that calculation? We could write a loop over all of the single-image tensors that are stacked within our validation set tensor, valid_3_tens, which has a shape of [1010,28,28] representing 1,010 images. But there is a better way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we pass each stacked images from our validation data and compare it to the stacked mean of our trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1488, 0.1145, 0.1158,  ..., 0.1129, 0.1419, 0.1669]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_dist = mnist_distance(valid_3_tens, mean3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it returned the distance for every single image as a vector (i.e., a rank-1 tensor) of length 1,010 (the number of 3s in our validation set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic trick is that PyTorch, when it tries to perform a simple subtraction operation between two tensors of different ranks, will use *broadcasting*. That is, it will automatically expand the tensor with the smaller rank to have the same size as the one with the larger rank. Broadcasting is an important capability that makes tensor code much easier to write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, PyTorch treats mean3, a rank-2 tensor representing a single image, as if it were 1,010 copies of the same image, and then subtracts each of those copies from each 3 in our validation set. What shape would you expect this tensor to have? Try to figure it out yourself before you look at the answer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_3_tens-mean3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:\n",
    "\n",
    "PyTorch doesn't actually copy mean3 1,010 times. It pretends it were a tensor of that shape, but doesn't actually allocate any additional memory\n",
    "It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).\n",
    "\n",
    "Next in *mnist_distance* we see *abs*. You might be able to guess now what this does when applied to a tensor. It applies the method to each individual element in the tensor, and returns a tensor of the results (that is, it applies the method \"elementwise\"). So in this case, we'll get back 1,010 matrices of absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use mnist_distance to figure out whether an image is a 3 or not by using the following logic: if the distance between the digit in question and the ideal 3 is less than the distance to the ideal 7, then it's a 3. This function will automatically do broadcasting and be applied elementwise,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_3(x): return mnist_distance(x,mean3) < mnist_distance(x,mean7)\n",
    "\n",
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to broadcasting, we can also test it on the full validation set of 3s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the accuracy for each of the 3s and 7s by taking the average of that function for all 3s and its inverse for all 7s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9511))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3s =      is_3(valid_3_tens).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting over 90% accuracy on both 3s and 7s, and we've seen how to define a metric conveniently using broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to *Stochastic Gradient Descent (SGD) topic* after the above broadcasting topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The MNIST Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have our independent variables *x* â€”these are the images themselves. We'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using *view*, which is a PyTorch method that changes the shape of a tensor without changing its contents. *-1* is a special parameter to *view* that means \"make this axis as big as necessary to fit all the data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a label for each image. We'll use 1 for 3s and 0 for 7s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *Dataset* in PyTorch is required to return a tuple of *(x,y)* when indexed. Python provides a *zip* function which, when combined with *list*, provides a simple way to get this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an (initially random) weight for every pixel (this is the initialize step in our seven-step process):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function weights * pixels won't be flexible enough. You might remember from high school math that the formula for a line is *y=w*x+b; we still need the *b*. We'll initialize it to a random number too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks, the *w* in the equation *y=w*x+b is called the *weights*, and the *b* is called the *bias*. Together, the weights and bias make up the *parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate a prediction for one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.4661], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could use a Python *for loop* to calculate the prediction for each image, that would be very slow. In this case, there's an extremely convenient mathematical operation that calculates w*x for every row of a matrixâ€”it's called *matrix multiplication*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, matrix multiplication is represented with the *@* operator. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.4661],\n",
       "        [  2.1309],\n",
       "        [ -1.8237],\n",
       "        ...,\n",
       "        [-14.3697],\n",
       "        [-13.6408],\n",
       "        [  5.2929]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, so our accuracy for each item can be calculated (using broadcasting, so no loops!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [ True],\n",
       "        [False],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [False]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7135366201400757"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the change in accuracy is for a small change in one of the weights (note that we have to ask PyTorch not to calculate gradients as we do this, which is what with *torch.no_grad()* is doing here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7135366201400757"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some loss function that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.\n",
    "\n",
    "So, we need to choose a loss function. The obvious approach would be to use accuracy, which is our metric, as our loss function as well. In this case, we would calculate our prediction for each image, collect these values to calculate an overall accuracy, and then calculate the gradients of each weight with respect to that overall accuracy.\n",
    "\n",
    "Unfortunately, we have a significant technical problem here. The gradient of a function is its slope, or its steepness, which can be defined as rise over runâ€”that is, how much the value of the function goes up or down, divided by how much we changed the input. We can write this in mathematically as: *(y_new - y_old) / (x_new - x_old)*. This gives us a good approximation of the gradient when *x_new* is very similar to *x_old*, meaning that their difference is very small. But accuracy only changes at all when a prediction changes from a 3 to a 7, or vice versa. The problem is that a small change in weights from *x_old* to *x_new* isn't likely to cause any prediction to change, so *(y_new - y_old)* will almost always be 0. In other words, the gradient is 0 almost everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very small change in the value of a weight will often not actually change the accuracy at all. This means it is not useful to use accuracy as a loss functionâ€”if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number. In mathematical terms, accuracy is a function that is constant almost everywhere (except at the threshold, 0.5), so its derivative is nil almost everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. So what does a \"slightly better prediction\" look like, exactly? Well, in this case, it means that if the correct answer is a 3 the score is a little higher, or if the correct answer is a 7 the score is a little lower.\n",
    "\n",
    "Let's write such a function now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, *prds*, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n",
    "\n",
    "The purpose of the loss function is to measure the difference between predicted values and the true values â€” that is, the *targets* (aka *labels*). Let's make another argument, trgts, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
    "\n",
    "So, for instance, suppose we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence *(0.9)* that the first was a 3, with slight confidence *(0.4)* that the second was a 7, and with fair confidence *(0.2)*, but incorrectly, that the last was a 7. This would mean our loss function would receive these values as its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgts  = tensor([1,0,1])\n",
    "prds   = tensor([0.9, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a first try at a loss function that measures the distance between *predictions* and *targets*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using a new function, *torch.where(a,b,c)*. This is the same as running the list comprehension *[b[i] if a[i] else c[i] for i in range(len(a))]*, except it works on tensors, at C/CUDA speed. In plain English, this function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it on our prds and trgts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this function returns a lower number when predictions are more accurate, when accurate predictions are more confident (higher absolute values), and when inaccurate predictions are less confident. In PyTorch, we always assume that a lower value of a loss function is better. Since we need a scalar for the final loss, *mnist_loss* takes the mean of the previous tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(prds,trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we change our prediction for the one \"false\" target from *0.2* to *0.8* the loss will go down, indicating that this is a better prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2333)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(tensor([0.9, 0.4, 0.8]),trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with mnist_loss as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly thatâ€”let's take a look."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
